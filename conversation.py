import os
from openai import OpenAI
from config import Config
import logging
import traceback

logger = logging.getLogger(__name__)
# Configure logging to output to console with detailed format
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class ConversationManager:
    def __init__(self):
        """Initialize conversation manager - now database-only knowledge base"""
        self._client = None  # Lazy initialization
        self.conversation_history = []
        self.model = "got-4.1-nano"  # Using reliable model
        self.system_prompt = "" # This will primarily come from the coaching agent
        self.slide_content_presented = set()  # Track which slides' content has been presented
        
        # Load AI Coach Personality from the centralized system prompt manager
        try:
            from slide_module_simplified.system_prompt_manager import get_system_prompt_manager
            prompt_manager = get_system_prompt_manager()
            if prompt_manager.base_prompt:
                logger.info("‚úÖ Loaded AI Coach Personality from centralized system")
            else:
                logger.warning("‚ö†Ô∏è Centralized system prompt not available. Ensure database is initialized.")
                logger.info("üí° Initialize with: python app.py (starts database initialization)")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not load AI Coach Personality: {e}")
            # Continue - system prompt will be provided by coaching manager
    
    def refresh_knowledge_base(self):
        """Refresh knowledge base - now no-op since we use database lessons"""
        logger.info("üîÑ Knowledge base refresh - using database lessons only")
        # Knowledge base is now managed by LessonCoachingManager from database
        # This method is kept for backward compatibility but does nothing
    
    @property
    def client(self):
        """Lazy initialization of OpenAI client"""
        if self._client is None:
            api_key = Config.OPENAI_API_KEY
            if not api_key or api_key == "YOUR_OPENAI_API_KEY_HERE":
                raise ValueError(
                    "‚ùå OpenAI API key not set or invalid.\n"
                    "üîë Get a new key from: https://platform.openai.com/api-keys\n"
                    "üìù Update OPENAI_API_KEY in config.py or set as environment variable"
                )
            self._client = OpenAI(api_key=api_key)
        return self._client
        
    def set_system_prompt(self, prompt: str, clear_history: bool = False):
        """Set the system prompt for the conversation. Optionally clear history.
           This prompt is typically generated by the coaching agent with context.
        """
        self.system_prompt = prompt
        logger.info(f"ü§ñ System prompt updated: {len(prompt)} characters")
        if clear_history: # Note: Clearing history might be handled externally now
            self.clear_history()
    
    def add_message(self, role, content):
        """Add a message to the conversation history."""
        self.conversation_history.append({"role": role, "content": content})
    
    def get_response(self, user_input, current_slide=None, lesson_id=None):
        """Get a response from the GPT model with complete context."""
        try:
            # Check if user has indicated readiness to move on
            if self._is_ready_to_move_on(user_input):
                # Check if we were just explaining something
                if len(self.conversation_history) >= 2:
                    last_assistant_msg = next((msg["content"] for msg in reversed(self.conversation_history) 
                                            if msg["role"] == "assistant"), None)
                    if last_assistant_msg and any(phrase in last_assistant_msg.lower() for phrase in 
                        ["let me explain", "here's why", "the reason is", "this is because", 
                         "to understand this", "let's break this down", "here's how"]):
                        return "Great! Now that you understand that, let's move on to the next topic."
                
                return self._generate_transition_response()

            # Prepare messages with system prompt and conversation history
            messages = [{"role": "system", "content": self.system_prompt}]
            
            # Add conversation history with context - using 10 messages for better personalization
            # while still maintaining reasonable performance
            for msg in self.conversation_history[-10:]:  # Increased from 5 to 10 messages
                messages.append(msg)
            
            # Add current user input
            messages.append({"role": "user", "content": user_input})

            logger.debug(f"Prepared {len(messages)} messages for API call. System prompt length: {len(self.system_prompt)}")
            
            # Get response from OpenAI with simplified parameters
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7  # Consistent temperature for reliable responses
            )

            # Extract and store response
            ai_response = response.choices[0].message.content
            
            # Track if this response presents slide content
            if current_slide is not None and self._is_slide_content_presentation(ai_response):
                self.slide_content_presented.add(current_slide)
                logger.info(f"üìä Marked slide {current_slide} content as presented")
            
            self.add_message("assistant", ai_response)

            logger.info("‚úÖ Received response from LLM")
            return ai_response

        except Exception as e:
            logger.error(f"‚ùå Error getting response from LLM: {e}")
            import traceback
            traceback.print_exc()
            raise

    def _is_ready_to_move_on(self, user_input):
        """Check if user has indicated they're ready to move on."""
        ready_indicators = [
            "yes", "yep", "yeah", "sure", "okay", "ok", "fine", "alright", "got it",
            "makes sense", "i understand", "i get it", "no questions", "no", "nope",
            "i see", "i see what you mean", "that's clear", "that makes sense",
            "i follow", "i'm following", "got that", "understood", "clear",
            "that's clear now", "i understand now", "i get it now"
        ]
        
        # Check if user input is a simple acknowledgment
        user_input_lower = user_input.lower().strip()
        return user_input_lower in ready_indicators

    def _generate_transition_response(self):
        """Generate a response to transition to the next topic."""
        # Check conversation history to determine if we've covered the current topic
        if len(self.conversation_history) >= 2:
            last_assistant_msg = next((msg["content"] for msg in reversed(self.conversation_history) 
                                     if msg["role"] == "assistant"), None)
            
            if last_assistant_msg:
                last_msg_lower = last_assistant_msg.lower()
                
                # Check for different types of previous messages to generate appropriate transitions
                if "does that make sense" in last_msg_lower:
                    return "Great! Let's move on to the next topic."
                elif "do you have any questions" in last_msg_lower:
                    return "Perfect! Since you don't have any questions, let's continue with our next topic."
                elif "would you like to" in last_msg_lower:
                    return "Alright! Let's proceed with the next topic then."
                elif "shall we" in last_msg_lower:
                    return "Excellent! Let's move forward with our next topic."
                elif "let's talk about" in last_msg_lower or "let's discuss" in last_msg_lower:
                    # If we just introduced a topic and user confirmed understanding
                    return "Great! Now that we've covered that, let's move on to our next topic."
        
        # Default transition response
        return "Perfect! Let's continue with our next topic."
    
    def clear_history(self):
        """Clear the conversation history."""
        self.conversation_history = []
        logger.info("üóëÔ∏è Conversation history cleared")
    
    def get_status(self):
        """Get current status of conversation manager"""
        return {
            'system_prompt_set': bool(self.system_prompt),
            'system_prompt_length': len(self.system_prompt) if self.system_prompt else 0,
            'knowledge_source': 'database_lessons',
            'conversation_history_length': len(self.conversation_history),
            'note': 'Knowledge base now managed by LessonCoachingManager from database'
        }

    def _is_slide_content_presentation(self, response):
        """Check if the response is presenting slide content."""
        # Look for patterns that indicate slide content presentation
        presentation_indicators = [
            "let's talk about",
            "let's discuss",
            "let's look at",
            "let's explore",
            "let's go through",
            "let's examine",
            "let's review",
            "let's cover",
            "let's learn about",
            "let's understand",
            "let's dive into",
            "let's focus on",
            "let's analyze",
            "let's break down",
            "let's investigate",
            "let's consider",
            "let's study",
            "let's examine",
            "let's look into",
            "let's explore the concept of"
        ]
        
        response_lower = response.lower()
        return any(indicator in response_lower for indicator in presentation_indicators)

    def has_presented_slide_content(self, slide_index):
        """Check if the content for a specific slide has been presented."""
        return slide_index in self.slide_content_presented

    def clear_slide_presentation_history(self):
        """Clear the history of presented slide content."""
        self.slide_content_presented.clear()
        logger.info("üóëÔ∏è Cleared slide presentation history")
